# -*- coding: utf-8 -*-
"""20cd7c25-deca-47ae-b927-80f6f6242bce (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CUCNcGVpqcUw2H38Uby4KtL5EzcncehY

Описание проекта. Телеком

Компания "ТелеДом", предоставляющая услуги связи, стремится сократить количество уходящих клиентов. С этой целью представители компании будут предлагать специальные промокоды и индивидуальные условия абонентам, намеревающимся прекратить обслуживание. Для заблаговременного выявления таких пользователей оператору требуется прогнозная модель, способная определять вероятность расторжения договора. Сотрудниками компании были собраны персональные сведения о части клиентов, включая данные об используемых тарифных планах и подключенных сервисах. Поставленная задача - создать на основе этой информации модель, прогнозирующую вероятность оттока абонентов.

Описание услуг

Оператор предоставляет два основных типа услуг:
1. **Стационарная телефонная связь**. Телефон можно подключить к нескольким линиям одновременно.
2. **Интернет**. Подключение бывает двух типов:
   - Через телефонную линию **DSL** (англ. digital subscriber line — «цифровая абонентская линия»);
   - **Оптоволоконный кабель** (англ. fiber optic).

Также абонентам доступны дополнительные услуги:
- **Интернет-безопасность**: антивирус (*Device Protection*) и блокировка опасных сайтов (*Online Security*);
- **Выделенная линия технической поддержки** (*Tech Support*);
- **Облачное хранилище файлов** для резервного копирования данных (*Online Backup*);
- **Стриминговое телевидение** (*Streaming TV*);
- **Каталог фильмов** (*Streaming Movies*).

За услуги клиенты могут платить **ежемесячно** или **раз в 1–2 года**. Доступны различные способы расчёта и возможность получить **электронный чек**.

Описание данных

Данные хранятся в **SQLite** — СУБД, в которой база данных представлена одним файлом. Она состоит из нескольких таблиц:
- `contract` — информация о договорах;
- `personal` — персональные данные клиентов;
- `internet` — информация об интернет-услугах;
- `phone` — информация об услугах телефонии.

### Таблица `contract`
- `customerID` — ID абонента;
- `BeginDate` — дата начала действия договора;
- `EndDate` — дата окончания действия договора;
- `Type` — тип оплаты: раз в год-два или ежемесячно;
- `PaperlessBilling` — электронный расчётный лист;
- `PaymentMethod` — тип платежа;
- `MonthlyCharges` — расходы за месяц;
- `TotalCharges` — общие расходы абонента.

### Таблица `personal`
- `customerID` — ID пользователя;
- `gender` — пол;
- `SeniorCitizen` — является ли абонент пенсионером;
- `Partner` — есть ли у абонента супруг или супруга;
- `Dependents` — есть ли у абонента дети.

### Таблица `internet`
- `customerID` — ID пользователя;
- `InternetService` — тип подключения;
- `OnlineSecurity` — блокировка опасных сайтов;
- `OnlineBackup` — облачное хранилище файлов для резервного копирования данных;
- `DeviceProtection` — антивирус;
- `TechSupport` — выделенная линия технической поддержки;
- `StreamingTV` — стриминговое телевидение;
- `StreamingMovies` — каталог фильмов.

### Таблица `phone`
- `customerID` — ID пользователя;
- `MultipleLines` — подключение телефона к нескольким линиям одновременно.
"""

!pip3 install catboost
!pip3 install phik
!pip install torchmetrics

!wget https://code.s3.yandex.net/data-scientist/ds-plus-final.db

# ==========================
# Стандартные библиотеки Python
# ==========================
import os
import re
import sqlite3
import time
from types import SimpleNamespace

# ==========================
# Визуализация и анализ данных
# ==========================
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import phik
import seaborn as sns
from IPython.display import display
from tqdm import tqdm
import plotly.express as px

# ==========================
# PyTorch и связанные библиотеки
# ==========================
import torch
import torch.nn as nn
from torchmetrics.classification import BinaryAccuracy, AUROC

# ==========================
# Scikit-learn: модели, трансформеры, метрики, поиск гиперпараметров
# ==========================
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.compose import ColumnTransformer
from sklearn.dummy import DummyClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.experimental import enable_halving_search_cv
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    ConfusionMatrixDisplay,
    roc_auc_score,
    roc_curve,
)
from sklearn.metrics import auc as sklearn_auc
from sklearn.model_selection import (
    GridSearchCV,
    HalvingGridSearchCV,
    KFold,
    train_test_split,
)
from sklearn.preprocessing import (
    MaxAbsScaler,
    OneHotEncoder,
    OrdinalEncoder,
    PowerTransformer,
    StandardScaler,
)

# ==========================
# imbalanced-learn (imblearn)
# ==========================
from imblearn.pipeline import Pipeline

# ==========================
# CatBoost
# ==========================
from catboost import CatBoostClassifier

def get_non_numeric_entries(df, column_name):
    try:
        if column_name not in df.columns:
            print(f"Столбец '{column_name}' не найден в DataFrame.")
            return []

        pattern = r'[ ,a-zA-Zа-яА-Я]'
        mask = df[column_name].astype(str).str.contains(pattern, na=False, regex=True)
        non_numeric_values = df.loc[mask, column_name].unique().tolist()

        count = len(non_numeric_values)
        print(f"Столбец '{column_name}': найдено {count} значений с нечисловыми символами.")
        if count > 0:
            print(non_numeric_values[:5], "..." if count > 5 else "")
        else:
            print("Нечисловые значения отсутствуют.")

        return non_numeric_values

    except Exception as e:
        print(f"Ошибка при анализе столбца '{column_name}': {e}")
        return []

RANDOM_STATE = 120525

def load_selected_tables(db_name, tables):

    db_path = f'./{db_name}'
    result = {}

    try:
        if not os.path.exists(db_path):
            print(f"Файл базы данных {db_path} не найден.")
            return result

        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            existing_tables = [table[0] for table in cursor.fetchall()]

            for table in tables:
                if table in existing_tables:
                    query = f"SELECT * FROM {table}"
                    result[table] = pd.read_sql_query(query, conn)
                    print(f"Таблица {table} успешно загружена: {result[table].shape[0]} строк, {result[table].shape[1]} столбцов")
                else:
                    print(f"Таблица {table} не найдена в базе данных.")

    except sqlite3.Error as e:
        print(f"Ошибка при работе с базой данных: {e}")
    except Exception as e:
        print(f"Общая ошибка: {e}")

    return result

db_name = 'ds-plus-final.db'
tables = ['contract', 'personal', 'internet', 'phone']
dataframes = load_selected_tables(db_name, tables)

contract_new = dataframes.get('contract', pd.DataFrame())
personal_new = dataframes.get('personal', pd.DataFrame())
internet_new = dataframes.get('internet', pd.DataFrame())
phone_new = dataframes.get('phone', pd.DataFrame())

print("\nТаблица contract_new:")
if not contract_new.empty:
    display(contract_new.head())
else:
    print("Таблица contract_new пуста.")

print("\nТаблица personal_new:")
if not personal_new.empty:
    display(personal_new.head())
else:
    print("Таблица personal_new пуста.")

print("\nТаблица internet_new:")
if not internet_new.empty:
    display(internet_new.head())
else:
    print("Таблица internet_new пуста.")

print("\nТаблица phone_new:")
if not phone_new.empty:
    display(phone_new.head())
else:
    print("Таблица phone_new пуста.")

"""Исследовательский анализ и предобработка данных

Анализ и предобработка contract_new (информация о договоре)
"""

contract_new.info()
contract_new.head()

def explore_unique_values(df):

    for column in df:
        unique_count = df[column].nunique()
        unique_values = df[column].unique().tolist()
        print(f"Столбец '{column}' содержит {unique_count} уникальных значений:")
        print(f"{unique_values[:10]}{'...' if unique_count > 10 else ''}\n")

explore_unique_values(contract_new)

def filter_by_end_date(df, filter_value='No', columns_to_show=['BeginDate', 'EndDate', 'TotalCharges']):
    try:
        missing_cols = [col for col in columns_to_show if col not in df.columns]
        if missing_cols:
            print(f"Ошибка: Столбцы {missing_cols} не найдены в DataFrame.")
            return pd.DataFrame()

        filtered_df = df.loc[df['EndDate'] == filter_value, columns_to_show]

        if not filtered_df.empty:
            print(f"\nНайдено {len(filtered_df)} строк, где EndDate = '{filter_value}':")
            print(filtered_df.head())
        else:
            print(f"\nСтрок с EndDate = '{filter_value}' не найдено.")

        return filtered_df

    except Exception as e:
        print(f"Ошибка при фильтрации данных: {e}")
        return pd.DataFrame()

filtered_data = filter_by_end_date(contract_new)

contract_new.loc[contract_new['TotalCharges'] == ' ', ['BeginDate', 'EndDate', 'TotalCharges']]

"""# Предварительные выводы

- **Размер данных**: Таблица `contract_new` включает 8 столбцов и 7043 записи.
- **Пропуски**: Пропусков в данных нет.
- **Столбец `customerID`**: Содержит уникальные идентификаторы клиентов.
- **Столбцы `BeginDate` и `EndDate`**: Хранят даты начала и окончания действия договора. Значение `No` в `EndDate` указывает на активный договор на 01.02.2020. Эти столбцы подлежат удалению, так как привязаны к конкретным временным интервалам и могут искажать предсказания для более поздних дат. Перед удалением необходимо создать новые признаки:
  - **`active_contract`**: Бинарный признак, где `0` — для `EndDate = 'No'`, `1` — для дат в `EndDate`. Этот признак будет целевым в объединённом датафрейме для обучения моделей.
  - **`duration_contract`**: Признак, отражающий продолжительность договора. Для расчёта продолжительности значения `No` в `EndDate` следует заменить на `2020-02-01` (дата актуальности данных, указанная руководителем проекта).
- **Категориальные признаки** (`Type`, `PaperlessBilling`, `PaymentMethod`): Требуют кодирования:
  - `OneHotEncoder` для линейных моделей.
  - `OrdinalEncoder` для древовидных моделей в составе Pipeline перед обучением.
- **Числовые признаки**:
  - `MonthlyCharges`: Содержит числовые значения, готов к использованию.
  - `TotalCharges`: Имеет тип `object`, требует преобразования в `float64`. Пробелы в `TotalCharges` следует заменить на `0`, так как отсутствие значения предположительно указывает на отсутствие оплат.
- **Стиль названий**: Рекомендуется привести названия столбцов к «змеиному_регистру» (snake_case) для единообразия.
"""

contract_new['active_contract'] = contract_new['EndDate'].ne('No').astype(int)
contract_new[['EndDate', 'active_contract']].head()

contract_new['BeginDate'] = pd.to_datetime(contract_new['BeginDate'], format='%Y-%m-%d')
print(f"Тип данных BeginDate: {contract_new['BeginDate'].dtype}")

contract_new['EndDate'] = contract_new['EndDate'].replace('No', '2020-02-01')
contract_new['EndDate'] = pd.to_datetime(contract_new['EndDate'], format='%Y-%m-%d')
print(contract_new['EndDate'].head())

contract_new['duration_contract'] = (contract_new['EndDate'] - contract_new['BeginDate']).dt.days
print(contract_new[['BeginDate', 'EndDate', 'duration_contract']].head())

contract_new.drop(columns=['BeginDate', 'EndDate'], inplace=True)
print("Столбцы после удаления:", contract_new.columns.tolist())

contract_new['TotalCharges'] = contract_new['TotalCharges'].replace(' ', 0).astype('float64')
print(f"Тип данных TotalCharges: {contract_new['TotalCharges'].dtype}")
print(contract_new['TotalCharges'].head())

contract_new.columns = [re.sub(r'(?<!^)(?=[A-Z])', '_', col).lower() for col in contract_new.columns]
contract_new.rename(columns={'customer_i_d': 'customer_id'}, inplace=True)
print("Итоговые названия столбцов:", contract_new.columns.tolist())

try:
    from IPython.display import display
    use_display = True
except ImportError:
    use_display = False

contract_new = dataframes.get('contract', pd.DataFrame())

print("\nИнформация о DataFrame:")
print(contract_new.info())

print("\nПервые 5 строк:")
if not contract_new.empty:
    if use_display:
        display(contract_new.head())
    else:
        print(contract_new.head())
else:
    print("Таблица contract_new пуста.")

"""Анализ и предобработка personal_new (персональные данные клиента)"""

personal_new.info()
personal_new.head()

explore_unique_values(personal_new)

for column in personal_new.columns:
    unique_vals = personal_new[column].unique()
    num_unique = len(unique_vals)
    sample = unique_vals[:5]

    print(f'Колонка: {column}')
    print(f'Уникальных значений: {num_unique}')
    print(f'Пример значений: {sample} {"..." if num_unique > 5 else ""}')
    print(f'Тип данных: {personal_new[column].dtype}')
    print('-' * 50)

"""# Предварительные выводы

- Датафрейм `personal_new` содержит **5 признаков** и **7043 объекта**  
- Датафрейм **не содержит пропусков**  
- Признак `customerID` содержит **идентификаторы клиентов**  
- Признаки `gender`, `SeniorCitizen`, `Partner` и `Dependents` — **бинарные категориальные**  
  - Требуется трансформировать:  
    - `OneHotEncoder` (для «линейных» моделей)  
    - `OrdinalEncoder` (для «деревянных» моделей)  
  - В `Pipeline` перед обучением модели  

- Особенности признака `SeniorCitizen`:  
  - Отличается от других бинарных категориальных признаков **числовыми значениями**  
  - Для унификации требуется:  
    - Заменить `0` → `No`, `1` → `Yes`  
    - Привести тип данных к `object`  

- **Стиль названий признаков**:  
  - Желательно привести к **«змеиному_стилю»**  
"""

class SeniorCitizenMapper(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X = X.copy()
        X['SeniorCitizen'] = X['SeniorCitizen'].astype('object')
        return X

assert personal_new['SeniorCitizen'].notna().all(), "Есть пропуски в SeniorCitizen после преобразования"

personal_new.columns = (
    personal_new.columns
    .str.replace('([a-z])([A-Z])', r'\1_\2', regex=True)
    .str.lower()
    .str.replace('i_d', 'id')
)

print(personal_new.info())
personal_new.head()

"""Анализ и предобработка internet_new (информация об интернет-услугах)"""

print(internet_new.info())
internet_new.head()

for col in internet_new.columns:
    unique_vals = internet_new[col].unique()
    print(
        f'Признак "{col}"\n'
        f'Уникальных значений: {len(unique_vals)}\n'
        f'Тип данных: {internet_new[col].dtype}\n'
        f'Значения: {np.sort(unique_vals) if internet_new[col].dtype != "object" else unique_vals}\n'
        f'{"-"*50}'
    )

"""# Предварительные выводы

- Датафрейм `internet_new` содержит **8 признаков** и **5517 объектов**  
- Датафрейм **не содержит пропусков**  
- Признак `customerID` содержит **идентификаторы клиентов**  
- Категориальные признаки для кодирования:  
  `InternetService`, `OnlineSecurity`, `OnlineBackup`,  
  `DeviceProtection`, `TechSupport`, `StreamingTV`, `StreamingMovies`  
  - Методы кодирования:  
    - `OneHotEncoder` (для линейных моделей)  
    - `OrdinalEncoder` (для деревянных моделей)  
  - Преобразование выполнять в `Pipeline`  

- **Рекомендация по стилю**:  
  Привести названия признаков к **snake_case**  
"""

internet_new.columns = (
    internet_new.columns
    .str.replace('([a-z])([A-Z])', r'\1_\2', regex=True)
    .str.lower()
    .str.replace('i_d', 'id')
    .str.replace('t_v', 'tv')
)

internet_new.columns.tolist()

internet_new.info(show_counts=True)
internet_new.head(3)

"""Анализ и предобработка phone_new (информация об услугах телефонии)"""

print(phone_new.info())
phone_new.head()

"""# Предварительные выводы

- Датафрейм `phone_new` содержит:
  - **2 признака**
  - **6361 объект**
  
- **Качество данных**:
  - Пропуски отсутствуют

- **Структура данных**:
  - `customerID` - идентификаторы клиентов
  - `MultipleLines` - бинарный категориальный признак

- **Требуемые преобразования**:
  - Для `MultipleLines`:
    - `OneHotEncoder` (линейные модели)
    - `OrdinalEncoder` (деревянные модели)
    - Встраивать в `Pipeline` перед обучением

- **Рекомендации**:
  - Привести названия признаков к `snake_case`
"""

phone_new.columns = (
    phone_new.columns
    .str.replace('([a-z])([A-Z])', r'\1_\2', regex=True)
    .str.lower()
    .str.replace('i_d', 'id')
)

phone_new.columns.to_list()

phone_new.info(show_counts=True)
phone_new.head(5)

"""# Объединение данных

## Процесс объединения:
- Объединяем выбранные признаки в единый датафрейм  
- Используем **customer_id** в качестве ключа объединения  
  (идентификатор клиента присутствует во всех датафреймах)  
"""

for df_name in ['contract_new', 'personal_new', 'internet_new', 'phone_new']:
    df = globals()[df_name]
    print(f'Размерность датафрейма "{df_name}": {df.shape}')

"""# Объединение датафреймов

## Ключевые датафреймы:
- `contract_new` - содержит информацию о договорах  
- `personal_new` - содержит данные о клиентах  

## Особенности объединения:
- Одинаковое количество объектов в `contract_new` и `personal_new`  
- Полное совпадение идентификаторов клиентов (`customer_id`)  
- Объединение выполняется через метод `join`  

## Работа с дополнительными датафреймами:
- `internet_new` и `phone_new` содержат меньше объектов  
- Используется левое объединение (`left join`)  
- Отсутствующие значения интерпретируются как:  
  - `No` (не приобретённая услуга)  
  - `NoValue` (отсутствие информации) - предпочтительный вариант  
"""

total_new = personal_new.join(
    contract_new.set_index('customer_id'),
    on='customer_id'
)

total_new = total_new.join(
    internet_new.set_index('customer_id'),
    on='customer_id',
    how='left'
)

total_new = total_new.join(
    phone_new.set_index('customer_id'),
    on='customer_id',
    how='left'
)

total_new = total_new.fillna('NoPackage')
total_new = total_new.fillna(0)

total_new.shape

"""# Предварительное выделение тренировочной выборки

## Параметры разделения:
- Метод: `train_test_split`
- Параметры:
  - `random_state=120525` (фиксированная случайность)
  - `test_size=0.25` (соотношение 75/25)

## Особенности обработки:
- Анализ и трансформация выполняются **только** на тренировочной выборке
- Объединение признаков и целевой переменной в единый датафрейм для:
  - Анализа взаимозависимостей переменных
  - Сохранения согласованных разделенных выборок для моделей
"""

features = total_new.drop('active_contract', axis=1)
target = total_new['active_contract']

features_train, features_test, target_train, target_test = train_test_split(
    features,
    target,
    test_size=0.25,
    stratify=target,
    random_state=RANDOM_STATE
)

total_new_train = features_train.join(target_train)

train_counts = target_train.value_counts()
test_counts = target_test.value_counts()

balance_df = pd.DataFrame({
    'Тренировочная выборка': train_counts,
    'Тестовая выборка': test_counts
}).T
balance_df.columns = ['Класс 0', 'Класс 1']
display(balance_df)

for name, counts in [('Тренировочная', train_counts), ('Тестовая', test_counts)]:
    ratio = counts[0] / counts[1]
    print(f'{name} выборка: соотношение классов {ratio:.2f}:1')

display(total_new_train.head())

display(total_new_train.describe(include='all'))

"""Исследовательский анализ объединённого датафрейма"""

total_new_train.info()
total_new_train.head(5)

feature_descriptions = {
    'customer_id': 'идентификатор абонента',
    'gender': 'пол',
    'senior_citizen': 'пенсионер',
    'partner': 'наличие супруга',
    'dependents': 'наличие детей',
    'type': 'тип оплаты',
    'paperless_billing': 'электронный расчётный лист',
    'payment_method': 'тип платежа',
    'monthly_charges': 'расходы за месяц',
    'total_charges': 'общие расходы',
    'active_contract': 'активный договор (целевой)',
    'duration_contract': 'продолжительность договора (дни)',
    'internet_service': 'тип подключения',
    'online_security': 'блокировка опасных сайтов',
    'online_backup': 'облачное хранилище',
    'device_protection': 'антивирус',
    'tech_support': 'техподдержка',
    'streaming_tv': 'стриминговое ТВ',
    'streaming_movies': 'каталог фильмов',
    'multiple_lines': 'многолинейный телефон'
}

pd.DataFrame.from_dict(feature_descriptions, orient='index', columns=['Описание'])

for feature in total_new_train.columns:
    if feature not in ['customer_id', 'active_contract']:
        print(f'\nАнализ признака: {feature} ({feature_descriptions.get(feature, "Без описания")})')

        feature_dtype = total_new_train[feature].dtype
        n_unique = total_new_train[feature].nunique()

        stats = total_new_train.groupby('active_contract')[feature].describe()
        display(stats)

        plt.figure(figsize=(10, 5))

        if feature_dtype == 'object' or n_unique < 10:
            sns.countplot(data=total_new_train, x=feature, hue='active_contract')
            plt.title(f'Распределение категориального признака: {feature}')
        else:
            sns.histplot(data=total_new_train, x=feature, hue='active_contract',
                         kde=True, stat='density', common_norm=False, alpha=0.6)
            plt.title(f'Нормированное распределение непрерывного признака: {feature}')

        plt.xticks(rotation=30)
        plt.tight_layout()
        plt.show()

numeric_features = ['monthly_charges', 'total_charges', 'duration_contract']
print(f'Числовые признаки ({len(numeric_features)}):', numeric_features)

categorical_features = [col for col in total_new_train.columns
                       if col not in numeric_features + ['customer_id', 'active_contract']]
print(f'\nКатегориальные признаки ({len(categorical_features)}):', categorical_features)

display(total_new_train[numeric_features].head(2))
display(total_new_train[categorical_features].head(2))

"""# Предварительные выводы по тренировочной выборке

## Общие характеристики:
- **Размерность**: 20 признаков, 7043 объекта
- **Типы признаков**:
  - 3 категориальных
  - 27 числовых
- **Проблемы данных**:
  - Дисбаланс классов в категориальных признаках
  - Отклонения от нормального распределения в числовых
  - Наличие выбросов

## Анализ целевого признака:
- `active_contract` - бинарный категориальный
- **Характеристики**:
  - Не сбалансирован (перевес класса 1 - активные контракты)
  - Пропуски отсутствуют
  - Целевые значения имеются для всех объектов

## Анализ признаков

### Пол (gender)
Мужчин и женщин почти поровну: ушедшие — 51% мужчин (2269), оставшиеся — 54% (446). Без перекосов, пол вряд ли влияет на уход.

### Пенсионеры (senior_citizen)
Пенсионеров мало: 85% ушедших (3782) и 79% оставшихся (650) — не пенсионеры. Оставшиеся чуть чаще пожилые, возможно, они лояльнее.

### Наличие супруга (partner)
Ушедшие — 55% (2434) одиночки, оставшиеся — 64% (531) с супругом. Семейные реже уходят, вероятно, из-за общих тарифов.

### Наличие детей (dependents)
Без детей: 71% ушедших (3165) и 67% оставшихся (557). Разница небольшая, семьи с детьми чуть лояльнее.

### Тип оплаты (type)
Помесячная оплата доминирует: 58% ушедших (2597), 38% оставшихся (312). Долгосрочные контракты удерживают лучше.

### Электронный счёт (paperless_billing)
Электронные счета: 58% ушедших (2570), 66% оставшихся (547). Оставшиеся чаще за цифровизацию, возможно, связано с возрастом.

### Тип платежа (payment_method)
Электронный чек лидирует: 35% ушедших (1541), 32% оставшихся (264). Метод оплаты особо не влияет на уход.

### Расходы за месяц (monthly_charges)
У ушедших топ — 20.05 (45 клиентов), у оставшихся — 19.4 (6). Разброс большой, у ушедших много дешевых тарифов. Нужна гистограмма.

### Общие расходы (total_charges)
У ушедших среднее — 2067.3, разброс большой (std 2188.6). У оставшихся — 2385.3, разброс меньше (std 1584). Оставшиеся платят больше. Нули у ушедших подозрительны.

### Продолжительность договора (duration_contract)
У ушедших — 896 дней в среднем, у оставшихся — 923. Медиана выше у оставшихся (913.5 против 702). Нули у ушедших — баг или новые клиенты?

### Тип подключения (internet_service)
Оптоволокно: 42% ушедших (1883), 55% оставшихся (454). Быстрый интернет, похоже, удерживает клиентов.

### Дополнительные услуги
- **Online Security, Tech Support**: У ушедших 50–51% не берут, у оставшихся чуть меньше. Не особо влияет.
- **Online Backup, Device Protection**: У оставшихся 51–52% берут, у ушедших — 46% нет. Допы могут удерживать.
- **Streaming TV/Movies**: У оставшихся 53–55% смотрят, у ушедших — 41% нет. Стриминг — плюс к лояльности.

### Многолинейный телефон (multiple_lines)
У ушедших 52% (2302) без телефона, у оставшихся 62% (514) с ним. Семейные, вероятно, чаще берут телефон.

## Итог
Оставшиеся — чаще семейные, с долгосрочными контрактами, любят стриминг и оптоволокно, платят больше. Ушедшие — одиночки, с помесячной оплатой, на дешевых тарифах, уходят быстро. Числовые признаки с большим разбросом, нули у ушедших надо проверить. Рекомендуется построить гистограммы и изучить корреляции, чтобы понять, что удерживает клиентов.

## Обработка категориальных признаков:
- Признаки с пропусками:
  - Оставить без обработки (причины пропусков неизвестны)
- **Методы кодирования**:
  - `OneHotEncoder` - для линейных моделей
  - `OrdinalEncoder` - для деревянных моделей
- **Исключение**: не кодируется только целевой признак

## Обработка числовых признаков:
- **Признаки для нормализации**:
  - `monthly_charges`
  - `total_charges`
  - `duration_contract`

## Корреляционный анализ:
- **Требуется**:
  - Проверить все признаки на корреляцию
  - Исключить:
    - Признаки с сильной мультиколлинеарностью
    - Признаки со статистически незначимой корреляцией

Анализ мультиколлинеарности
"""

multicollinearity_matrix = (
    total_new_train
    .drop('customer_id', axis=1)
    .phik_matrix(interval_cols=numeric_features)
)

display(multicollinearity_matrix.round(2))

plt.figure(figsize=(12, 10))
sns.heatmap(
    multicollinearity_matrix,
    annot=True,
    fmt=".1f",
    cmap='YlOrRd',
    vmin=0,
    vmax=1,
    linewidths=.5
)
plt.title('Матрица корреляций (PhiK) между признаками', pad=20)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

"""# Отбор признаков для обучения моделей

## Критерии отбора признаков:

1. **Корреляция с целевым признаком**:
   - Минимальный порог: ≥ 0.3
   - Признаки с корреляцией ниже порога исключаются

2. **Мультиколлинеарность**:
   - Максимальный допустимый порог между признаками: ≤ 0.75
   - Для мультиколлинеарных пар оставляется признак с:
     - Более высокой корреляцией с целевой переменной
     - Более простой интерпретацией

## Процедура отбора:
- Анализ матрицы корреляций
- Последовательное исключение признаков:
  - Сначала по низкой корреляции с целевой переменной
  - Затем по высокой межфакторной корреляции
- Фиксация окончательного набора признаков
"""

def non_multicollinear_features(m, target_feature, v_min, v_max):

    columns = []
    append = True

    for c in m.columns:
        if ((m[c][target_feature] > v_min) & (c != target_feature)):
            for i in m.index:
                if ((c != i) & (c != target_feature) & (c not in columns) & (i not in columns)):
                    if m[c][i] > v_max:
                        if m[c][target_feature] < m[i][target_feature]:
                            append = False
                            break
            if append == True: columns.append(c)
            append = True

    return columns

columns = non_multicollinear_features(multicollinearity_matrix, 'active_contract', .03, .75)

print('Не мультиколлинеарные признаки, обладающие статистически значимой парной корреляцией с целевым признаком:')
columns

cat_features = [feat for feat in columns
               if feat in categorical_features]

num_features = [feat for feat in columns
               if feat in numeric_features]

print(f'Категориальные признаки ({len(cat_features)}):\n{cat_features}\n')
print(f'Числовые признаки ({len(num_features)}):\n{num_features}')

"""## Подготовка данных

Подготовка данных для обучения модели. Разделение данных на две выборки, при масштабировании и кодировании должны быть учтены особенности данных и моделей.

Объединенный датафрейм ранее уже был разделен на обучающую и тренировочную выборки, а также на целевой и не целевые признаки. На треннировочной выборке выбраны не мультиколлинеарные признаки, обладающие статистически значимой парной корреляцией с целевым признаком.

Названия этих признаков собраны в переменную `columns`. Учитывая выше сказанное, требуется использовать ранее созданные выборки, но в выборках с «фичами» оставить только признаки, перечисленные в переменной `columns`.

Также перед обучением моделей следует удалить далее не используемые переменные, т.к. процесс обучения моделей ресурсоемкий.

"""

X_train_filtered = features_train[columns].copy()
X_test_filtered = features_test[columns].copy()

vars_to_delete = [
    'contract_new', 'personal_new', 'internet_new', 'phone_new',
    'features', 'target', 'total_new_train'
]

for var in vars_to_delete:
    if var in locals():
        del globals()[var]

print(X_train_filtered.info())
X_train_filtered.head()

print(pd.DataFrame(target_train).info())
pd.DataFrame(target_train).head()

print(X_test_filtered.info())
X_test_filtered.head()

print(pd.DataFrame(target_test).info())
pd.DataFrame(target_test).head()

"""Обучение моделей машинного обучения

Функция для настройки и обучения модели
"""

def run_model_with_search(X_train, y_train, pipeline, param_grid, model_results, timing_results):
    start = time.time()

    search = HalvingGridSearchCV(
        estimator=pipeline,
        param_grid=param_grid,
        cv=4,
        scoring='roc_auc',
        error_score='raise',
        random_state=RANDOM_STATE
    )

    search.fit(X_train, y_train)
    duration = time.time() - start

    model_results.append(search)
    timing_results.append(duration)

    return model_results, timing_results

"""Функция для печати результатов обучения"""

def display_model_summary(results_list, time_list, model_label, show_grid=False):
    print(f"\nМодель         : {model_label}")
    print(f"Метрика ROC AUC: {results_list[-1].best_score_}")
    print(f"Время          : {time_list[-1]:.2f} секунд")
    print("Параметры      :", results_list[-1].best_estimator_[-1].get_params())
    print("-" * 30)

    if show_grid:
        print("Результаты подбора гиперпараметров:")
        display(pd.DataFrame(results_list[-1].cv_results_)[[
            'params', 'mean_train_score', 'mean_test_score'
        ]])

"""Функция для визуализации результатов кросс-валидации"""

def plot_model_scores(results_list):
    df_scores = pd.DataFrame(results_list[-1].cv_results_)[[
        'mean_test_score', 'mean_train_score'
    ]]

    plt.figure(figsize=(8, 6))
    plt.scatter(df_scores.index, df_scores['mean_train_score'], label='Train ROC AUC', color='blue', alpha=0.6)
    plt.scatter(df_scores.index, df_scores['mean_test_score'], label='Test ROC AUC', color='orange', alpha=0.6)

    plt.title('ROC AUC для итераций подбора гиперпараметров')
    plt.xlabel('Итерация')
    plt.ylabel('ROC AUC')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.7)

    plt.show()

"""Вычисление весов классов на основе целевой переменной"""

class_distribution = target_train.value_counts(normalize=True)
class_weights = {
    1: class_distribution.get(1, 0),
    0: class_distribution.get(0, 0)
}

class_weights

"""Функция для генерации значений гиперпараметров в центре и по краям диапазона"""

def get_three_point_range(a, b, as_int=False):
    mid = (a + b) / 2
    left = a + (mid - a) / 2
    right = b - (b - mid) / 2

    if as_int:
        return [int(left), int(mid), int(right)]

    return [left, mid, right]

"""Инициализация списков для хранения результатов"""

model_results = []
timing_results = []

"""Обучение модели LogisticRegression

Инициализация модели LogisticRegression
"""

logreg_model = LogisticRegression(
    random_state=RANDOM_STATE,
    class_weight='balanced'
)

"""Построение трансформера признаков"""

logreg_transformer = ColumnTransformer([
    ('cat_ohe', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_features),
    ('num_power', PowerTransformer(), num_features)
], remainder='drop', verbose_feature_names_out=False)

"""Создание пайплайна"""

logreg_pipeline = Pipeline([
    ('transform', logreg_transformer),
    ('clf', logreg_model)
])

"""Итеративный подбор гиперпараметра C"""

logreg_transformer = ColumnTransformer([
    ('cat_ohe', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_features),
    ('num_power', PowerTransformer(), num_features)
], remainder='drop', verbose_feature_names_out=False)

logreg_pipeline = Pipeline([
    ('transform', logreg_transformer),
    ('clf', logreg_model)
])

C_range = [0.111, 0.5, 0.999]

while C_range[1] - C_range[0] > 0.01:
    C_range = get_three_point_range(C_range[0], C_range[-1], as_int=False)

    param_grid = [{
        'clf__solver': ['liblinear', 'lbfgs', 'newton-cg'],
        'clf__C': C_range
    }]

    model_results, timing_results = run_model_with_search(
        X_train_filtered,
        target_train,
        logreg_pipeline,
        param_grid,
        model_results,
        timing_results
    )

    display_model_summary(model_results, timing_results, 'LogisticRegression', show_grid=True)

    best_C = model_results[-1].best_estimator_.named_steps['clf'].get_params()['C']

    if len(C_range) > 1:
        if C_range[0] == best_C:
            C_range = [C_range[0], (C_range[0] + (C_range[1] - C_range[0]) / 2), C_range[1]]
        elif C_range[2] == best_C:
            C_range = [C_range[1], (C_range[1] + (C_range[2] - C_range[1]) / 2), C_range[2]]

"""Визуализация результатов модели"""

plot_model_scores(model_results)

"""Обучение модели RandomForestClassifier

Инициализация модели RandomForestClassifier
"""

rf_model = RandomForestClassifier(
    random_state=RANDOM_STATE
)

ordinal_encoder = OrdinalEncoder(
    handle_unknown='use_encoded_value',
    unknown_value=-1
)

"""Построение трансформера признаков"""

rf_transformer = ColumnTransformer([
    ('cat_ord', ordinal_encoder, cat_features),
    ('num_scale', MaxAbsScaler(), num_features)
], remainder='drop', verbose_feature_names_out=False)

"""Сборка пайплайна"""

rf_pipeline = Pipeline([
    ('transform', rf_transformer),
    ('clf', rf_model)
])

"""Итеративный подбор гиперпараметров"""

max_depth_range = [1, 100, 200]
n_estimators_range = [1, 100, 200]

while (
    (max_depth_range[1] - max_depth_range[0] > 10) or
    (n_estimators_range[1] - n_estimators_range[0] > 10)
):
    max_depth_range = get_three_point_range(max_depth_range[0], max_depth_range[-1], as_int=True)
    n_estimators_range = get_three_point_range(n_estimators_range[0], n_estimators_range[-1], as_int=True)

    param_grid = [{
        'clf__max_features': ['sqrt', 'log2', None, 1.0],
        'clf__max_depth': max_depth_range,
        'clf__n_estimators': n_estimators_range
    }]

    model_results, timing_results = run_model_with_search(
        features_train,
        target_train,
        rf_pipeline,
        param_grid,
        model_results,
        timing_results
    )

    display_model_summary(model_results, timing_results, 'RandomForestClassifier', show_grid=True)

    best_max_depth = model_results[-1].best_estimator_[-1].get_params()['max_depth']
    if max_depth_range[0] == best_max_depth:
        max_depth_range = [max_depth_range[0],
                           int(max_depth_range[0] + (max_depth_range[1] - max_depth_range[0]) / 2),
                           max_depth_range[1]]
    elif max_depth_range[2] == best_max_depth:
        max_depth_range = [max_depth_range[1],
                           int(max_depth_range[1] + (max_depth_range[2] - max_depth_range[1]) / 2),
                           max_depth_range[2]]

    best_n_estimators = model_results[-1].best_estimator_[-1].get_params()['n_estimators']
    if n_estimators_range[0] == best_n_estimators:
        n_estimators_range = [n_estimators_range[0],
                              int(n_estimators_range[0] + (n_estimators_range[1] - n_estimators_range[0]) / 2),
                              n_estimators_range[1]]
    elif n_estimators_range[2] == best_n_estimators:
        n_estimators_range = [n_estimators_range[1],
                              int(n_estimators_range[1] + (n_estimators_range[2] - n_estimators_range[1]) / 2),
                              n_estimators_range[2]]

plot_model_scores(model_results)

"""Обучение модели CatBoostClassifier"""

catboost_model = CatBoostClassifier(
    logging_level='Silent',
    random_state=RANDOM_STATE
)

"""Преобразование признаков"""

catboost_transformer = ColumnTransformer([
    ('cat_ord', OrdinalEncoder(), cat_features),
    ('num_scale', MaxAbsScaler(), num_features)
], remainder='drop', verbose_feature_names_out=False)

"""Pipeline"""

catboost_pipeline = Pipeline([
    ('transform', catboost_transformer),
    ('clf', catboost_model)
])

"""Начальные диапазоны параметров"""

depth_range = [1, 10, 15]
estimators_range = [500, 1000, 1500]
learning_rate_range = [0.001, 0.5, 0.999]

"""Поиск лучших гиперпараметров"""

while (
    (depth_range[1] - depth_range[0] > 1) and
    (estimators_range[1] - estimators_range[0] > 10) and
    (learning_rate_range[1] - learning_rate_range[0] > 0.01)
):
    depth_range = get_three_point_range(depth_range[0], depth_range[-1], as_int=True)
    estimators_range = get_three_point_range(estimators_range[0], estimators_range[-1], as_int=True)
    learning_rate_range = get_three_point_range(learning_rate_range[0], learning_rate_range[-1], as_int=False)

    param_grid = [{
        'clf__depth': depth_range,
        'clf__n_estimators': estimators_range,
        'clf__learning_rate': learning_rate_range
    }]

    model_results, timing_results = run_model_with_search(
        features_train,
        target_train,
        catboost_pipeline,
        param_grid,
        model_results,
        timing_results
    )

    display_model_summary(model_results, timing_results, 'CatBoostClassifier', show_grid=True)

    best_depth = model_results[-1].best_estimator_[-1].get_params()['depth']
    if depth_range[0] == best_depth:
        depth_range = [depth_range[0],
                       int(depth_range[0] + (depth_range[1] - depth_range[0]) / 2),
                       depth_range[1]]
    elif depth_range[2] == best_depth:
        depth_range = [depth_range[1],
                       int(depth_range[1] + (depth_range[2] - depth_range[1]) / 2),
                       depth_range[2]]

    best_estimators = model_results[-1].best_estimator_[-1].get_params()['n_estimators']
    if estimators_range[0] == best_estimators:
        estimators_range = [estimators_range[0],
                            int((estimators_range[0] + estimators_range[1]) / 2),
                            estimators_range[1]]
    elif estimators_range[2] == best_estimators:
        estimators_range = [estimators_range[1],
                            int((estimators_range[1] + estimators_range[2]) / 2),
                            estimators_range[2]]

    best_lr = model_results[-1].best_estimator_[-1].get_params()['learning_rate']
    if learning_rate_range[0] == best_lr:
        learning_rate_range = [learning_rate_range[0],
                               (learning_rate_range[0] + learning_rate_range[1]) / 2,
                               learning_rate_range[1]]
    elif learning_rate_range[2] == best_lr:
        learning_rate_range = [learning_rate_range[1],
                               (learning_rate_range[1] + learning_rate_range[2]) / 2,
                               learning_rate_range[2]]

plot_model_scores(model_results)

"""Обучение модели NeuralNetwork

Кодирование категориальных признаков
"""

features_train_proc = features_train.copy()
features_test_proc = features_test.copy()

ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')

features_train_cat = pd.DataFrame(
    ohe.fit_transform(features_train_proc[cat_features]),
    columns=ohe.get_feature_names_out(cat_features),
    index=features_train_proc.index
)

features_test_cat = pd.DataFrame(
    ohe.transform(features_test_proc[cat_features]),
    columns=ohe.get_feature_names_out(cat_features),
    index=features_test_proc.index
)

features_train_num = features_train_proc[num_features]
features_test_num = features_test_proc[num_features]

features_train_proc = features_train_num.join(features_train_cat)
features_test_proc = features_test_num.join(features_test_cat)

"""Масштабирование числовых признаков"""

scaler = StandardScaler()
features_train_proc[num_features] = scaler.fit_transform(features_train_num)
features_test_proc[num_features] = scaler.transform(features_test_num)

"""Перевод в тензоры"""

if 'customer_id' in features_train_proc.columns:
    features_train_proc = features_train_proc.drop(columns='customer_id')
if 'customer_id' in features_test_proc.columns:
    features_test_proc = features_test_proc.drop(columns='customer_id')

for col in features_train_proc.columns:
    try:
        pd.to_numeric(features_train_proc[col])
    except ValueError:
        print(f"Column {col} in features_train_proc is still non-numeric.")

for col in features_test_proc.columns:
    try:
        pd.to_numeric(features_test_proc[col])
    except ValueError:
        print(f"Column {col} in features_test_proc is still non-numeric.")

features_train_nn = features_train_proc.astype('float32')
features_test_nn = features_test_proc.astype('float32')
target_train_nn = target_train.astype('float32')
target_test_nn = target_test.astype('float32')

X_train_torch = torch.tensor(features_train_nn.values)
X_test_torch = torch.tensor(features_test_nn.values)
y_train_torch = torch.tensor(target_train_nn.values).flatten()
y_test_torch = torch.tensor(target_test_nn.values).flatten()

"""Определение модели"""

model = nn.Sequential(
    nn.Linear(X_train_torch.shape[1], 504),
    nn.Tanh(),
    nn.Linear(504, 252),
    nn.Tanh(),
    nn.Linear(252, 252),
    nn.Tanh(),
    nn.Dropout(0.2),
    nn.Linear(252, 42),
    nn.Tanh(),
    nn.Dropout(0.8),
    nn.Linear(42, 1),
    nn.Dropout(0.4)
)

"""Метрики и функция потерь"""

bin_ac = BinaryAccuracy()
auc = AUROC(task='binary')
loss_fn = nn.BCEWithLogitsLoss()

"""Кросс-валидация"""

history_nn = {
    "epoch": [],
    "loss": [],
    "roc_auc": [],
    "accuracy": []
}

k_folds = 8
kfold = KFold(n_splits=k_folds, shuffle=True, random_state=RANDOM_STATE)

metrics = {"fold": [], "loss": [], "auc": [], "accuracy": []}

start_time = time.time()

for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_train_torch)):
    model.train()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.5)

    for epoch in tqdm(range(200)):
        preds = model(X_train_torch).flatten()
        loss_value = loss_fn(preds, y_train_torch)

        optimizer.zero_grad()
        loss_value.backward()
        optimizer.step()

        if epoch >= 100:
            with torch.no_grad():
                model.eval()
                preds_val = model(X_train_torch).flatten()
                acc = bin_ac(preds_val, y_train_torch).item()
                roc = auc(preds_val, y_train_torch).item()

                history_nn["epoch"].append(epoch)
                history_nn["loss"].append(loss_value.item())
                history_nn["roc_auc"].append(roc)
                history_nn["accuracy"].append(acc)

    metrics["fold"].append(fold_idx)
    metrics["loss"].append(loss_value.item())
    metrics["accuracy"].append(acc)
    metrics["auc"].append(roc)

end_time = time.time()

"""Сбор и сохранение результатов"""

score_nn = np.mean(metrics['auc'])
print('ROC-AUC на кросс-валидации:', score_nn)

nn_result = SimpleNamespace()
nn_result.model_type = "NeuralNetwork"
nn_result.roc_auc_score = score_nn
nn_result.best_score_ = score_nn
nn_result.history = history_nn
nn_result.metrics = metrics
nn_result.params = {
    "epochs": 200,
    "lr": 0.5,
    "optimizer": "SGD"
}
nn_result.best_estimator_ = model
nn_result.training_time = end_time - start_time

"""Добавим в общие списки результатов"""

model_results.append(nn_result)
timing_results.append({
    "model": "NeuralNetwork",
    "time": nn_result.training_time
})

"""Визуализация метрик обучения нейросети"""

def plot_nn_metrics(history):
    plt.figure(figsize=(10, 5))
    plt.plot(history["epoch"], history["roc_auc"], label="ROC AUC")
    plt.plot(history["epoch"], history["loss"], label="Loss")
    plt.title("Метрики обучения нейросети")
    plt.xlabel("Epoch")
    plt.ylabel("Значение")
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.show()

plot_nn_metrics(history_nn)

"""Выбор лучшей модели

Поиск лучшей модели по ROC AUC
"""

best_model_result = model_results[0]
best_model_time = timing_results[0]

for i in range(len(model_results)):
    if model_results[i].best_score_ > best_model_result.best_score_:
        best_model_result = model_results[i]
        best_model_time = timing_results[i]

print('Лучшее время выполнения    :', best_model_time)
print('Лучший показатель ROC AUC  :', best_model_result.best_score_)
print('Объект лучшей модели       :')
print(best_model_result)
print('Лучшие гиперпараметры модели:')
best_model_result.get_params()

"""## 🔍 Вывод по итогам подбора модели

В результате выбора модели на основе метрики **ROC AUC** наилучшие результаты показала модель **CatBoostClassifier** с гиперпараметрами:

```python
{
    'depth': 8,
    'learning_rate': 0.5,
    'n_estimators': 1000,
    'logging_level': 'Silent',
    'random_state': 120525
}

ROC AUC: 0.8885

Время обучения: 626.61 секунд

Тестирование лучшей модели
"""

start_infer_time = time.time()

y_pred_labels = best_model_result.predict(features_test)
y_pred_probs = best_model_result.predict_proba(features_test)

end_infer_time = time.time()
inference_duration = end_infer_time - start_infer_time

"""Анализ протестированной модели"""

roc_auc_score_result = roc_auc_score(target_test, y_pred_probs[:, 1])

print(f'Значение ROC AUC: {roc_auc_score_result:.6f}')
print(f'Время инференса: {inference_duration:.2f} секунд')

"""Цель данного проекта достигнута. В результате тестирования выбранной модели машинного обучения с подобранными гиперпараметрами получена метрика ROC AUC выше требуемого уровня данного параметра в 0.9 более чем на 0.1."""

dummy = DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE)
dummy.fit(features_train, target_train)

dummy_probs = dummy.predict_proba(features_test)

dummy_roc_auc = roc_auc_score(target_test, dummy_probs[:, 1])

print(f'ROC AUC DummyClassifier (most_frequent): {dummy_roc_auc:.6f}')
print(f'ROC AUC CatBoost (лучшая модель)       : {roc_auc_score_result:.6f}')
print(f'Разница ROC AUC                        : {roc_auc_score_result - dummy_roc_auc:.6f}')

"""Модель на CatBoost реально работает, и это не просто "пальцем в небо". Базовая модель (DummyClassifier), которая всегда выбирает самый частый класс, набрала ровно 0.5 по ROC AUC — что означает абсолютно случайное угадывание.

В то время как наша обученная модель уверенно выдала ROC AUC ≈ 0.90, что говорит о хорошем качестве классификации и способности находить реальные закономерности в данных.

✅ Разница почти в 0.4 — это огромный задел, так что можно спокойно утверждать: модель действительно имеет смысл, и все старания по подготовке данных и настройке гиперпараметров были не зря.
"""

fpr_values, tpr_values, roc_thresholds = roc_curve(target_test, y_pred_probs[:, 1])
roc_auc_area = sklearn_auc(fpr_values, tpr_values)

plt.plot(
    fpr_values,
    tpr_values,
    color='darkorange',
    label=f'ROC-кривая (AUC = {roc_auc_area:.4f})'
)
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-кривая')
plt.legend(loc="lower right")
plt.show()

"""ROC-кривая демонстрирует выраженную выпуклость вверх, занимая значительную площадь внутри вписанного прямоугольника. Это говорит о том, что модель чаще всего корректно распознаёт целевые классы."""

accuracy_value = accuracy_score(target_test, y_pred_labels)
print('Показатель Accuracy:', accuracy_value)

"""Порядка 90% предсказаний модели оказываются верными, что свидетельствует о хорошем качестве. Однако стоит учитывать дисбаланс классов — модель может лучше предсказывать преобладающий класс (в данном случае класс 0 — договор не расторгнут). Подробное распределение по классам можно увидеть на матрице ошибок."""

conf_matrix = confusion_matrix(target_test, y_pred_labels)
conf_matrix_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=["Negative", "Positive"])
conf_matrix_display.plot()
plt.show()

"""Матрица ошибок показывает, что модель с высокой точностью определяет класс 0 (договор не расторгнут), допуская лишь около 2% ошибок. С классом 1 (договор расторгнут) ситуация хуже: правильно предсказано только около двух третей случаев. Следовательно, модель надёжно выявляет пользователей, остающихся с договором, но для выявления расторжений прогнозы менее точны."""

feature_importance_df = pd.DataFrame(
    best_model_result.best_estimator_[-1].feature_importances_,
    index=best_model_result.best_estimator_[:-1].get_feature_names_out(),
    columns=['Важность признака']
).sort_values(by='Важность признака', ascending=False)

feature_importance_df

"""Анализ важности признаков выявил явного лидера — продолжительность договора (duration_contract). За ним с заметным отрывом следует ежемесячная плата (monthly_charges). Эти факторы оказывают наибольшее влияние на предсказания модели. Наименее значимым оказался признак senior_citizen — его изменение почти не влияет на результат."""

hist_params = [
    ('duration_contract', 'Зависимость оттока клиентов от продолжительности договора'),
    ('monthly_charges', 'Зависимость оттока клиентов от расходов абонента за месяц'),
    ('type', 'Зависимость оттока клиентов от типа оплаты абонента (раз в год-два или ежемесячно)'),
    ('payment_method', 'Зависимость оттока клиентов от типа платежа абонента')
]

color_sequence = px.colors.qualitative.Set2

for col, title in hist_params:
    fig = px.histogram(
        total_new,
        x=col,
        color='active_contract',
        barmode='group',
        title=title,
        histfunc='count',
        color_discrete_sequence=color_sequence
    )

    fig.update_layout(
        title_font=dict(size=18, family='Arial', color='black'),
        xaxis_title=col.replace('_', ' ').capitalize(),
        yaxis_title='Количество клиентов',
        legend_title='Отток',
        bargap=0.15,
        plot_bgcolor='white',
        paper_bgcolor='white',
        font=dict(size=14)
    )
    fig.update_xaxes(showgrid=True, gridcolor='lightgrey')
    fig.update_yaxes(showgrid=True, gridcolor='lightgrey')

    fig.show()

"""## 📊 Анализ факторов оттока клиентов

---

### 📊 Зависимость оттока от продолжительности договора (`duration_contract`)
Клиенты чаще уходят в интервале **150–800 дней** — возможно, в этот период заканчиваются акции или накапливается неудовлетворённость.  
На ранних (<150 дней) и поздних сроках (>1000 дней) отток значительно ниже.

🧠 **Вывод:** середина жизненного цикла договора — **зона риска**, на этом этапе важно применять меры по удержанию.

---

### 📊 Месячные расходы и отток (`monthly_charges`)
Отток наблюдается во всех диапазонах расходов, от **~18\$ до ~115\$**

**Особо выделяются:**
- **19\$–25\$** — высокая плотность клиентов и заметный отток (до 5–8 уходов на значение).
- **99\$–106\$** — стабильный, но умеренный отток (1–3 ухода на значение).
- При **минимальных (<19\$)** и **максимальных расходах (>110\$)** — отток ниже, вероятно, из-за малого числа клиентов.

🧠 **Вывод:** диапазон **19\$–25\$** — **ключевая зона риска**. Возможно, клиенты чувствуют, что цена не соответствует ожиданиям по качеству услуг.

---

### 📊 Тип оплаты и отток (`type`)
- Самый высокий отток — у клиентов с **ежемесячной оплатой** ("Month-to-month").
- **Годовые** и **двухгодичные контракты** демонстрируют меньший отток.

🧠 **Вывод:** **долгосрочные планы повышают удержание**. Предложение бонусов за переход на них может сократить отток.

---

### 📊 Тип платежа и отток (`payment_method`)
- Наибольший отток у клиентов с **электронным чеком** и **автоплатежами** (по 317–350 уходов).
- **Самый низкий отток** — у тех, кто платит **почтовым чеком** (117 из 1612).

🧠 **Вывод:** несмотря на автоматизацию, такие клиенты чаще уходят. Возможно, метод платежа косвенно отражает поведение или удовлетворённость клиента.

## Анализ влияния признаков на отток клиентов

### Важные признаки

**1. `duration_contract`** – самый значимый фактор (32.5%)   
Чем дольше срок контракта, тем выше шанс, что клиент останется.

**2. `monthly_charges`** – влияет негативно  
 Более высокая ежемесячная плата связана с большей вероятностью оттока.

**3. `type`** – тип подключения  
🔌 Некоторые типы услуг (например, надёжный интернет) лучше удерживают клиентов.

**4. `payment_method`** – способ оплаты  
 Автоматические и удобные способы оплаты ассоциируются с лояльностью.

**5. Дополнительные услуги (`multiple_lines`, `device_protection`, `online_backup`)**  
 Наличие доп. сервисов говорит об активном использовании – такие клиенты реже уходят.

**6. Социальные признаки (`partner`, `dependents`, `senior_citizen`)**  
 Семейные клиенты и более молодые пользователи имеют тенденцию оставаться дольше.

---

###  Вывод

Модель показала, что **долгосрочные контракты**, **адекватные цены** и **подключение дополнительных услуг** способствуют удержанию клиентов.  
Это подтверждает, что модель действительно находит осмысленные зависимости.

# Общий вывод о проекте

Цель проекта — предсказание оттока клиентов компании «ТелеДом» — успешно достигнута. В качестве оптимального решения рекомендована модель CatBoostClassifier с гиперпараметрами:  
{
    'depth': 8,
    'learning_rate': 0.5,
    'n_estimators': 1000,
    'logging_level': 'Silent',
    'random_state': 120525
}`.  
При тестировании модель показала ROC AUC 0.903399, что превышает установленный порог 0.85.

# Рекомендации для заказчика

Модель CatBoostClassifier удовлетворяет текущим требованиям по качеству.

Рекомендуется пересмотреть подход к оценке результата, дополнительно рассчитывая бизнес-метрики, например, финансовые потери от ухода клиентов. Поскольку модель корректно предсказывает уход лишь у двух из трёх клиентов, важно улучшать точность именно этого класса.

# Рекомендации по работе с данными

Обратите внимание на качество исходных данных: типы переменных часто не оптимальны. Например, параметр TotalCharges хранится как object, хотя содержит числовые значения с плавающей точкой. Бинарные категориальные признаки (например, PaperlessBilling) лучше привести к типам bool или int8 — это упростит хранение без потери информации.

Также выявлены пропуски в данных, которые становятся заметны при объединении таблиц — отсутствует информация по некоторым услугам у клиентов. Рекомендуется провести дополнительную очистку и оптимизацию хранения данных.

# Итоговые выводы по признакам и моделям

Большинство признаков исходных таблиц имеют высокую мультиколлинеарность и слабую корреляцию с целевым признаком, поэтому для обучения были отобраны наиболее информативные:  

- Целевой признак: active_contract (статус договора). Рекомендуется хранить в бинарном виде.  
- Категориальные признаки: multiple_lines, paperless_billing, payment_method, tech_support, internet_service.  
- Числовые признаки: total_charges, duration_contract.

Использованные модели — LogisticRegression, RandomForestRegressor,  CatBoostClassifier и Neural Network — показали разные результаты. CatBoostClassifier продемонстрировала лучший ROC AUC и выбрана для дальнейшего применения с поддержкой кросс-валидации и оптимизации через Pipeline и HalvingGridSearchCV.

# Основные этапы работы

- Обновлены и подключены необходимые библиотеки, улучшено отображение в тетради.  
- Загружены и проверены данные из файлов contract_new, personal_new, internet_new и phone_new.  
- Проведен исследовательский анализ и предобработка каждого датафрейма.  
- Данные объединены в один общий датафрейм, выделена тренировочная выборка.  
- Выполнен анализ мультиколлинеарности и парной корреляции, отобраны значимые признаки.  
- Подготовлены данные к обучению.  
- Обучены и протестированы модели LogisticRegression, RandomForestRegressor и CatBoostClassifier.  
- По метрике ROC AUC выбрана лучшая модель.  
- Сформулированы общий вывод и рекомендации для заказчика.

# Рекомендации для бизнеса по снижению оттока

🔹 **Развивайте долгосрочные тарифы:**  
Клиенты с длительными контрактами уходят реже. Можно предложить бонусы за подключение на 12+ месяцев (например, скидки, бесплатные опции).

🔹 **Удерживайте клиентов с высокими платежами:**  
Пользователи с высокими ежемесячными затратами чаще уходят. Рассмотрите возможность персонализированных предложений для этой группы — бонусы, скидки или апгрейд услуг.

🔹 **Продвигайте дополнительные сервисы:**  
Наличие доп. опций (резервное копирование, защита устройств, множественные линии) снижает вероятность ухода. Важно предлагать эти опции как пакеты при подключении или продлении контракта.

🔹 **Упростите способы оплаты:**  
Автоматические методы оплаты (например, автосписание с карты) ассоциируются с более низким оттоком. Сделайте их максимально доступными и поощряйте их использование.

🔹 **Работайте с пожилыми клиентами:**  
Пожилые пользователи чаще уходят. Рекомендуется предоставить им дополнительные консультации, более простые тарифы или обучение по работе с услугами.

🔹 **Используйте модель для проактивной работы:**  
Модель можно интегрировать в CRM-систему для раннего выявления клиентов с высоким риском оттока и вовремя запускать удерживающие кампании.
"""